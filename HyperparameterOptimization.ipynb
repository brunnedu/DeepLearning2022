{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "538478bf-e811-4d68-ba5f-dd289a14fd6e",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f15b9-df83-4da5-8ead-9cfbab607c19",
   "metadata": {},
   "source": [
    "To optimize our hyperparameters we use Optuna which is an automatic hyperparameter optimization software framework that uses Bayesian Optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92846608-124b-4153-b69f-842d026ac21e",
   "metadata": {},
   "source": [
    "Each parameter to search over should have a value of the following format: `'parameter_name': ('type', lower_bound, upper_bound)`\n",
    "\n",
    "`'type'` can have one of 4 values:\n",
    "- `'int'`: search over integers in the interval **[lower_bound, upper_bound]** (uniform distribution)\n",
    "- `'int-log'`: search over powers of 2 in the interval **[2^lower_bound, 2^upper_bound]** (uniform distribution)\n",
    "- `'float'`: search over floating-point numbers in the interval **[lower_bound, upper_bound]** with each number having the same probability to be sampled (uniform distribution)\n",
    "- `'float-log'`: search over floating-point numbers in the interval **[lower_bound, upper_bound]** with smaller values having a higher probability to be sampled (uniform distribution in log domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4687bc60-0973-4362-88a9-2f6e637952e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.optuna import create_optuna_objective\n",
    "from src.dataset import get_imagenet_info, get_tiny_imagenet_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b69d67-5458-4fb6-ae01-8d47788f273f",
   "metadata": {},
   "source": [
    "### Pretext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf24ab-9614-4504-b1ce-135797bff195",
   "metadata": {},
   "source": [
    "This is an example of the optuna_pretext_script running on a small subset of the ImageNet dataset for only 2 epochs for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c5867bc-303b-4feb-a264-2f7ff93f5d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_info = get_imagenet_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c6643ab-28a4-4601-bbde-f6f4cc7faacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-13 12:11:05,102]\u001b[0m A new study created in memory with name: no-name-1032994b-76a2-4086-8323-69e1990fc667\u001b[0m\n",
      "| parameter              | value                                                                                                                                               |\n",
      "|:-----------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_test_2022-12-13_12-11-05                                                                                                                     |\n",
      "| aug_transform          | Compose(                                                                                                                                            |\n",
      "|                        |     RandomResizedCrop(size=(224, 224), scale=(0.32, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear), antialias=None)                            |\n",
      "|                        |     ColorJitter(brightness=[0.19999999999999996, 1.8], contrast=[0.19999999999999996, 1.8], saturation=[0.19999999999999996, 1.8], hue=[-0.2, 0.2]) |\n",
      "|                        |     RandomGrayscale(p=0.05)                                                                                                                         |\n",
      "|                        |     GaussianBlur(kernel_size=(23, 23), sigma=(1e-10, 0.2))                                                                                          |\n",
      "|                        |     RandomSolarize(threshold=0.7,p=0.2)                                                                                                             |\n",
      "|                        | )                                                                                                                                                   |\n",
      "| pretext_type           | our                                                                                                                                                 |\n",
      "| loss_alpha             | 1                                                                                                                                                   |\n",
      "| loss_symmetric         | True                                                                                                                                                |\n",
      "| n_train                | 90                                                                                                                                                  |\n",
      "| optimizer_kwargs       | {'lr': 0.00016216578196968584, 'weight_decay': 0}                                                                                                   |\n",
      "| num_epochs             | 2                                                                                                                                                   |\n",
      "| batch_size             | 64                                                                                                                                                  |\n",
      "| num_workers            | 4                                                                                                                                                   |\n",
      "| log_frequency          | 100                                                                                                                                                 |\n",
      "| cache_images           | True                                                                                                                                                |\n",
      "| resume_from_checkpoint | False                                                                                                                                               |\n",
      "| logger                 | <RootLogger root (INFO)>                                                                                                                            |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/1]\tTime 11.911s (11.911s)\tSpeed 5.4 samples/s\tLoss 4.17945 (4.17945)\n",
      "Epoch: [0][1/1]\tTime 4.842s (8.376s)\tSpeed 5.4 samples/s\tLoss 4.23318 (4.19497)\n",
      "Test: [0/0]\tTime 0.481 (0.481)\tLoss 4.0106 (4.0106)\n",
      "Accuracy: 0.100\n",
      "Saving best model to ./out/optuna_test_2022-12-13_12-11-05/best_model.pth.tar\n",
      "Saving checkpoint to ./out/optuna_test_2022-12-13_12-11-05/checkpoint.pth.tar\n",
      "Epoch: [1][0/1]\tTime 11.899s (11.899s)\tSpeed 5.4 samples/s\tLoss 3.97801 (3.97801)\n",
      "Epoch: [1][1/1]\tTime 4.822s (8.361s)\tSpeed 5.4 samples/s\tLoss 4.37567 (4.09289)\n",
      "Test: [0/0]\tTime 0.486 (0.486)\tLoss 3.7155 (3.7155)\n",
      "Accuracy: 0.100\n",
      "Saving checkpoint to ./out/optuna_test_2022-12-13_12-11-05/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_test_2022-12-13_12-11-05/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:11:59,798]\u001b[0m Trial 0 finished with value: 0.1 and parameters: {'lr': 0.00016216578196968584}. Best is trial 0 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                                                                                               |\n",
      "|:-----------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_test_2022-12-13_12-11-59                                                                                                                     |\n",
      "| aug_transform          | Compose(                                                                                                                                            |\n",
      "|                        |     RandomResizedCrop(size=(224, 224), scale=(0.32, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear), antialias=None)                            |\n",
      "|                        |     ColorJitter(brightness=[0.19999999999999996, 1.8], contrast=[0.19999999999999996, 1.8], saturation=[0.19999999999999996, 1.8], hue=[-0.2, 0.2]) |\n",
      "|                        |     RandomGrayscale(p=0.05)                                                                                                                         |\n",
      "|                        |     GaussianBlur(kernel_size=(23, 23), sigma=(1e-10, 0.2))                                                                                          |\n",
      "|                        |     RandomSolarize(threshold=0.7,p=0.2)                                                                                                             |\n",
      "|                        | )                                                                                                                                                   |\n",
      "| pretext_type           | our                                                                                                                                                 |\n",
      "| loss_alpha             | 1                                                                                                                                                   |\n",
      "| loss_symmetric         | True                                                                                                                                                |\n",
      "| n_train                | 90                                                                                                                                                  |\n",
      "| optimizer_kwargs       | {'lr': 4.382195768248061e-05, 'weight_decay': 0}                                                                                                    |\n",
      "| num_epochs             | 2                                                                                                                                                   |\n",
      "| batch_size             | 64                                                                                                                                                  |\n",
      "| num_workers            | 4                                                                                                                                                   |\n",
      "| log_frequency          | 100                                                                                                                                                 |\n",
      "| cache_images           | True                                                                                                                                                |\n",
      "| resume_from_checkpoint | False                                                                                                                                               |\n",
      "| logger                 | <RootLogger root (INFO)>                                                                                                                            |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/1]\tTime 12.018s (12.018s)\tSpeed 5.3 samples/s\tLoss 4.18067 (4.18067)\n",
      "Epoch: [0][1/1]\tTime 5.463s (8.740s)\tSpeed 4.8 samples/s\tLoss 4.08558 (4.15320)\n",
      "Test: [0/0]\tTime 0.521 (0.521)\tLoss 4.1144 (4.1144)\n",
      "Accuracy: 0.100\n",
      "Saving best model to ./out/optuna_test_2022-12-13_12-11-59/best_model.pth.tar\n",
      "Saving checkpoint to ./out/optuna_test_2022-12-13_12-11-59/checkpoint.pth.tar\n",
      "Epoch: [1][0/1]\tTime 12.224s (12.224s)\tSpeed 5.2 samples/s\tLoss 3.99168 (3.99168)\n",
      "Epoch: [1][1/1]\tTime 4.784s (8.504s)\tSpeed 5.4 samples/s\tLoss 4.01967 (3.99976)\n",
      "Test: [0/0]\tTime 0.488 (0.488)\tLoss 3.8701 (3.8701)\n",
      "Accuracy: 0.250\n",
      "Saving best model to ./out/optuna_test_2022-12-13_12-11-59/best_model.pth.tar\n",
      "Saving checkpoint to ./out/optuna_test_2022-12-13_12-11-59/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_test_2022-12-13_12-11-59/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:12:55,721]\u001b[0m Trial 1 finished with value: 0.25 and parameters: {'lr': 4.382195768248061e-05}. Best is trial 1 with value: 0.25.\u001b[0m\n",
      "| parameter              | value                                                                                                                                               |\n",
      "|:-----------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_test_2022-12-13_12-12-55                                                                                                                     |\n",
      "| aug_transform          | Compose(                                                                                                                                            |\n",
      "|                        |     RandomResizedCrop(size=(224, 224), scale=(0.32, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear), antialias=None)                            |\n",
      "|                        |     ColorJitter(brightness=[0.19999999999999996, 1.8], contrast=[0.19999999999999996, 1.8], saturation=[0.19999999999999996, 1.8], hue=[-0.2, 0.2]) |\n",
      "|                        |     RandomGrayscale(p=0.05)                                                                                                                         |\n",
      "|                        |     GaussianBlur(kernel_size=(23, 23), sigma=(1e-10, 0.2))                                                                                          |\n",
      "|                        |     RandomSolarize(threshold=0.7,p=0.2)                                                                                                             |\n",
      "|                        | )                                                                                                                                                   |\n",
      "| pretext_type           | our                                                                                                                                                 |\n",
      "| loss_alpha             | 1                                                                                                                                                   |\n",
      "| loss_symmetric         | True                                                                                                                                                |\n",
      "| n_train                | 90                                                                                                                                                  |\n",
      "| optimizer_kwargs       | {'lr': 5.763706327921896e-05, 'weight_decay': 0}                                                                                                    |\n",
      "| num_epochs             | 2                                                                                                                                                   |\n",
      "| batch_size             | 64                                                                                                                                                  |\n",
      "| num_workers            | 4                                                                                                                                                   |\n",
      "| log_frequency          | 100                                                                                                                                                 |\n",
      "| cache_images           | True                                                                                                                                                |\n",
      "| resume_from_checkpoint | False                                                                                                                                               |\n",
      "| logger                 | <RootLogger root (INFO)>                                                                                                                            |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/1]\tTime 12.559s (12.559s)\tSpeed 5.1 samples/s\tLoss 4.18067 (4.18067)\n",
      "Epoch: [0][1/1]\tTime 4.895s (8.727s)\tSpeed 5.3 samples/s\tLoss 4.08002 (4.15159)\n",
      "Test: [0/0]\tTime 0.497 (0.497)\tLoss 4.0995 (4.0995)\n",
      "Accuracy: 0.100\n",
      "Saving best model to ./out/optuna_test_2022-12-13_12-12-55/best_model.pth.tar\n",
      "Saving checkpoint to ./out/optuna_test_2022-12-13_12-12-55/checkpoint.pth.tar\n",
      "Epoch: [1][0/1]\tTime 12.743s (12.743s)\tSpeed 5.0 samples/s\tLoss 3.97120 (3.97120)\n",
      "Epoch: [1][1/1]\tTime 4.947s (8.845s)\tSpeed 5.3 samples/s\tLoss 4.04574 (3.99273)\n",
      "Test: [0/0]\tTime 0.515 (0.515)\tLoss 3.8212 (3.8212)\n",
      "Accuracy: 0.350\n",
      "Saving best model to ./out/optuna_test_2022-12-13_12-12-55/best_model.pth.tar\n",
      "Saving checkpoint to ./out/optuna_test_2022-12-13_12-12-55/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_test_2022-12-13_12-12-55/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:13:52,466]\u001b[0m Trial 2 finished with value: 0.35 and parameters: {'lr': 5.763706327921896e-05}. Best is trial 2 with value: 0.35.\u001b[0m\n",
      "| parameter              | value                                                                                                                                               |\n",
      "|:-----------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_test_2022-12-13_12-13-52                                                                                                                     |\n",
      "| aug_transform          | Compose(                                                                                                                                            |\n",
      "|                        |     RandomResizedCrop(size=(224, 224), scale=(0.32, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear), antialias=None)                            |\n",
      "|                        |     ColorJitter(brightness=[0.19999999999999996, 1.8], contrast=[0.19999999999999996, 1.8], saturation=[0.19999999999999996, 1.8], hue=[-0.2, 0.2]) |\n",
      "|                        |     RandomGrayscale(p=0.05)                                                                                                                         |\n",
      "|                        |     GaussianBlur(kernel_size=(23, 23), sigma=(1e-10, 0.2))                                                                                          |\n",
      "|                        |     RandomSolarize(threshold=0.7,p=0.2)                                                                                                             |\n",
      "|                        | )                                                                                                                                                   |\n",
      "| pretext_type           | our                                                                                                                                                 |\n",
      "| loss_alpha             | 1                                                                                                                                                   |\n",
      "| loss_symmetric         | True                                                                                                                                                |\n",
      "| n_train                | 90                                                                                                                                                  |\n",
      "| optimizer_kwargs       | {'lr': 1.0252853296032751e-05, 'weight_decay': 0}                                                                                                   |\n",
      "| num_epochs             | 2                                                                                                                                                   |\n",
      "| batch_size             | 64                                                                                                                                                  |\n",
      "| num_workers            | 4                                                                                                                                                   |\n",
      "| log_frequency          | 100                                                                                                                                                 |\n",
      "| cache_images           | True                                                                                                                                                |\n",
      "| resume_from_checkpoint | False                                                                                                                                               |\n",
      "| logger                 | <RootLogger root (INFO)>                                                                                                                            |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "\u001b[33m[W 2022-12-13 12:13:57,134]\u001b[0m Trial 3 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dustinbrunner/mambaforge/envs/dl_project/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/Users/dustinbrunner/Programming/ETH/HS22/Deep Learning/DeepLearning2022/src/optuna.py\", line 53, in objective\n",
      "    best_acc = run_pretext(**current_run_params)\n",
      "  File \"/Users/dustinbrunner/Programming/ETH/HS22/Deep Learning/DeepLearning2022/src/train.py\", line 311, in run_pretext\n",
      "    best_acc = train_model(\n",
      "  File \"/Users/dustinbrunner/Programming/ETH/HS22/Deep Learning/DeepLearning2022/src/train.py\", line 68, in train_model\n",
      "    train(experiment_id, model, train_loader, device, criterion, optimizer, epoch, logger, log_frequency)\n",
      "  File \"/Users/dustinbrunner/Programming/ETH/HS22/Deep Learning/DeepLearning2022/src/train.py\", line 111, in train\n",
      "    for i, (input, target) in enumerate(train_loader):\n",
      "  File \"/Users/dustinbrunner/mambaforge/envs/dl_project/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 628, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/Users/dustinbrunner/mambaforge/envs/dl_project/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1316, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/Users/dustinbrunner/mambaforge/envs/dl_project/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1282, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/Users/dustinbrunner/mambaforge/envs/dl_project/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1120, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/Users/dustinbrunner/mambaforge/envs/dl_project/lib/python3.9/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/Users/dustinbrunner/mambaforge/envs/dl_project/lib/python3.9/multiprocessing/connection.py\", line 262, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/Users/dustinbrunner/mambaforge/envs/dl_project/lib/python3.9/multiprocessing/connection.py\", line 429, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/Users/dustinbrunner/mambaforge/envs/dl_project/lib/python3.9/multiprocessing/connection.py\", line 936, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Users/dustinbrunner/mambaforge/envs/dl_project/lib/python3.9/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# run study\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_TRIALS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTIMEOUT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/dl_project/lib/python3.9/site-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/dl_project/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/envs/dl_project/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/mambaforge/envs/dl_project/lib/python3.9/site-packages/optuna/study/_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    230\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/mambaforge/envs/dl_project/lib/python3.9/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m~/Programming/ETH/HS22/Deep Learning/DeepLearning2022/src/optuna.py:53\u001b[0m, in \u001b[0;36mcreate_optuna_objective.<locals>.objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     51\u001b[0m     best_acc \u001b[38;5;241m=\u001b[39m run_downstream(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcurrent_run_params)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 53\u001b[0m     best_acc \u001b[38;5;241m=\u001b[39m \u001b[43mrun_pretext\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcurrent_run_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# return the accuracy this parameter combination achieved\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_acc\n",
      "File \u001b[0;32m~/Programming/ETH/HS22/Deep Learning/DeepLearning2022/src/train.py:311\u001b[0m, in \u001b[0;36mrun_pretext\u001b[0;34m(experiment_id, aug_transform, pretext_type, loss_alpha, loss_symmetric, imagenet_info, n_train, optimizer_kwargs, num_epochs, batch_size, num_workers, log_frequency, cache_images, resume_from_checkpoint)\u001b[0m\n\u001b[1;32m    308\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptimizer_kwargs)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m best_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mds_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mds_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_acc\n",
      "File \u001b[0;32m~/Programming/ETH/HS22/Deep Learning/DeepLearning2022/src/train.py:68\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(experiment_id, model, ds_train, ds_val, device, criterion, optimizer, num_epochs, batch_size, num_workers, resume_from_checkpoint, log_frequency, fix_seed, seed, logger)\u001b[0m\n\u001b[1;32m     64\u001b[0m     model, optimizer, start_epoch, best_acc \u001b[38;5;241m=\u001b[39m load_checkpoint(experiment_id, model, optimizer)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, num_epochs):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# train for one epoch\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_frequency\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# evaluate on validation set\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     acc \u001b[38;5;241m=\u001b[39m validate(experiment_id, model, val_loader, device, criterion, epoch, logger, log_frequency)\n",
      "File \u001b[0;32m~/Programming/ETH/HS22/Deep Learning/DeepLearning2022/src/train.py:111\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(experiment_id, model, train_loader, device, criterion, optimizer, epoch, logger, log_frequency)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# switch to training mode\u001b[39;00m\n\u001b[1;32m    109\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (\u001b[38;5;28minput\u001b[39m, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m    112\u001b[0m     curr_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    114\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m# cross entropy loss function expects long type\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/dl_project/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/mambaforge/envs/dl_project/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/dl_project/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/mambaforge/envs/dl_project/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/dl_project/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/mambaforge/envs/dl_project/lib/python3.9/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/dl_project/lib/python3.9/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/mambaforge/envs/dl_project/lib/python3.9/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/mambaforge/envs/dl_project/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from torchvision.transforms import Compose, RandomResizedCrop, RandomGrayscale, GaussianBlur, ColorJitter, RandomSolarize\n",
    "\n",
    "from src.optuna import create_optuna_objective\n",
    "\n",
    "aug_transform = Compose([\n",
    "    RandomResizedCrop(size=224, scale=(0.32, 1.0), ratio=(0.75, 1.3333333333333333)),\n",
    "    ColorJitter(brightness=0.8, contrast=0.8, saturation=0.8, hue=0.2),\n",
    "    RandomGrayscale(p=0.05),\n",
    "    GaussianBlur(kernel_size=23, sigma=(1e-10, 0.2)),\n",
    "    RandomSolarize(0.7, p=0.2),\n",
    "])\n",
    "\n",
    "RUN_PRETEXT_PARAMS = {\n",
    "    \"experiment_id\": \"optuna_test\",\n",
    "    \"pretext_type\": \"our\",\n",
    "    \"aug_transform\": aug_transform,\n",
    "    \"loss_alpha\": 1,\n",
    "    \"loss_symmetric\": True,\n",
    "    \"optimizer_kwargs\": {\n",
    "        \"lr\": (\"float-log\", 1e-5, 1e-3),\n",
    "        \"weight_decay\": 0,\n",
    "    },\n",
    "    \"batch_size\": 64,\n",
    "    \"num_workers\": 4,\n",
    "    \"log_frequency\": 100,\n",
    "    \"cache_images\": True,\n",
    "    \"resume_from_checkpoint\": False,\n",
    "    \"imagenet_info\": imagenet_info[:100],\n",
    "    \"n_train\": 90,\n",
    "    \"num_epochs\": 2,\n",
    "}\n",
    "\n",
    "# maximal number of trials to perform\n",
    "N_TRIALS = 1e9\n",
    "# stops search if last trial ended more than TIMEOUT seconds after the start\n",
    "TIMEOUT = 1e9\n",
    "\n",
    "# create objective function\n",
    "objective = create_optuna_objective(RUN_PRETEXT_PARAMS)\n",
    "\n",
    "# create study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# run study\n",
    "study.optimize(objective, n_trials=N_TRIALS, timeout=TIMEOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3fd4cb-7cdf-4b8f-88ae-84997b3cfb92",
   "metadata": {},
   "source": [
    "### Downstream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c1ce3f-d4b9-4009-9302-c6a0759cefff",
   "metadata": {},
   "source": [
    "This is an example of the optuna_downstream_script running on a small subset of the Tiny ImageNet dataset for only 2 epochs for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "744671c3-e502-4dd7-b0f3-93e00693f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_imagenet_info = get_tiny_imagenet_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9391a288-7a9c-467f-b020-a5f418ec7883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-13 12:14:30,438]\u001b[0m A new study created in memory with name: no-name-72835412-ffc7-4799-9c44-5bbaf16b7da7\u001b[0m\n",
      "| parameter              | value                                                               |\n",
      "|:-----------------------|:--------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-14-30                          |\n",
      "| use_aug_transform      | 1                                                                   |\n",
      "| n_train                | 90                                                                  |\n",
      "| optimizer_kwargs       | {'lr': 0.000125636508349156, 'weight_decay': 3.093222912503181e-05} |\n",
      "| num_epochs             | 2                                                                   |\n",
      "| batch_size             | 32                                                                  |\n",
      "| num_workers            | 0                                                                   |\n",
      "| log_frequency          | 100                                                                 |\n",
      "| cache_images           | True                                                                |\n",
      "| resume_from_checkpoint | False                                                               |\n",
      "| logger                 | <RootLogger root (INFO)>                                            |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/2]\tTime 0.925s (0.925s)\tSpeed 34.6 samples/s\tLoss 5.25919 (5.25919)\n",
      "Epoch: [0][2/2]\tTime 0.738s (0.844s)\tSpeed 35.2 samples/s\tLoss 5.32596 (5.28980)\n",
      "Test: [0/0]\tTime 0.159 (0.159)\tLoss 5.2528 (5.2528)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-14-30/checkpoint.pth.tar\n",
      "Epoch: [1][0/2]\tTime 0.861s (0.861s)\tSpeed 37.2 samples/s\tLoss 5.19349 (5.19349)\n",
      "Epoch: [1][2/2]\tTime 0.725s (0.818s)\tSpeed 35.9 samples/s\tLoss 5.08441 (5.13498)\n",
      "Test: [0/0]\tTime 0.168 (0.168)\tLoss 5.2514 (5.2514)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-14-30/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-14-30/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:14:36,309]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.000125636508349156, 'weight_decay': 3.093222912503181e-05, 'batch_size': 5}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "| parameter              | value                                                                  |\n",
      "|:-----------------------|:-----------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-14-36                             |\n",
      "| use_aug_transform      | 1                                                                      |\n",
      "| n_train                | 90                                                                     |\n",
      "| optimizer_kwargs       | {'lr': 0.00011804993641970345, 'weight_decay': 0.00016703792716335245} |\n",
      "| num_epochs             | 2                                                                      |\n",
      "| batch_size             | 64                                                                     |\n",
      "| num_workers            | 0                                                                      |\n",
      "| log_frequency          | 100                                                                    |\n",
      "| cache_images           | True                                                                   |\n",
      "| resume_from_checkpoint | False                                                                  |\n",
      "| logger                 | <RootLogger root (INFO)>                                               |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/1]\tTime 1.659s (1.659s)\tSpeed 38.6 samples/s\tLoss 5.30885 (5.30885)\n",
      "Epoch: [0][1/1]\tTime 0.719s (1.189s)\tSpeed 36.2 samples/s\tLoss 5.25483 (5.29324)\n",
      "Test: [0/0]\tTime 0.153 (0.153)\tLoss 5.3129 (5.3129)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-14-36/checkpoint.pth.tar\n",
      "Epoch: [1][0/1]\tTime 1.597s (1.597s)\tSpeed 40.1 samples/s\tLoss 5.20042 (5.20042)\n",
      "Epoch: [1][1/1]\tTime 0.716s (1.157s)\tSpeed 36.3 samples/s\tLoss 5.17512 (5.19311)\n",
      "Test: [0/0]\tTime 0.151 (0.151)\tLoss 5.2737 (5.2737)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-14-36/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-14-36/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:14:41,846]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.00011804993641970345, 'weight_decay': 0.00016703792716335245, 'batch_size': 6}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "| parameter              | value                                                                 |\n",
      "|:-----------------------|:----------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-14-41                            |\n",
      "| use_aug_transform      | 0                                                                     |\n",
      "| n_train                | 90                                                                    |\n",
      "| optimizer_kwargs       | {'lr': 8.035378899901043e-05, 'weight_decay': 1.3502324917332701e-05} |\n",
      "| num_epochs             | 2                                                                     |\n",
      "| batch_size             | 64                                                                    |\n",
      "| num_workers            | 0                                                                     |\n",
      "| log_frequency          | 100                                                                   |\n",
      "| cache_images           | True                                                                  |\n",
      "| resume_from_checkpoint | False                                                                 |\n",
      "| logger                 | <RootLogger root (INFO)>                                              |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/1]\tTime 1.628s (1.628s)\tSpeed 39.3 samples/s\tLoss 5.31408 (5.31408)\n",
      "Epoch: [0][1/1]\tTime 0.726s (1.177s)\tSpeed 35.8 samples/s\tLoss 5.25808 (5.29790)\n",
      "Test: [0/0]\tTime 0.150 (0.150)\tLoss 5.2979 (5.2979)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-14-41/checkpoint.pth.tar\n",
      "Epoch: [1][0/1]\tTime 1.657s (1.657s)\tSpeed 38.6 samples/s\tLoss 5.20173 (5.20173)\n",
      "Epoch: [1][1/1]\tTime 0.750s (1.203s)\tSpeed 34.7 samples/s\tLoss 5.19343 (5.19933)\n",
      "Test: [0/0]\tTime 0.150 (0.150)\tLoss 5.2819 (5.2819)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-14-41/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-14-41/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:14:47,450]\u001b[0m Trial 2 finished with value: 0.0 and parameters: {'use_aug_transform': 0, 'lr': 8.035378899901043e-05, 'weight_decay': 1.3502324917332701e-05, 'batch_size': 6}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "| parameter              | value                                                                |\n",
      "|:-----------------------|:---------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-14-47                           |\n",
      "| use_aug_transform      | 0                                                                    |\n",
      "| n_train                | 90                                                                   |\n",
      "| optimizer_kwargs       | {'lr': 1.097975098248139e-05, 'weight_decay': 5.476778159628229e-05} |\n",
      "| num_epochs             | 2                                                                    |\n",
      "| batch_size             | 32                                                                   |\n",
      "| num_workers            | 0                                                                    |\n",
      "| log_frequency          | 100                                                                  |\n",
      "| cache_images           | True                                                                 |\n",
      "| resume_from_checkpoint | False                                                                |\n",
      "| logger                 | <RootLogger root (INFO)>                                             |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/2]\tTime 0.866s (0.866s)\tSpeed 37.0 samples/s\tLoss 5.33424 (5.33424)\n",
      "Epoch: [0][2/2]\tTime 0.740s (0.834s)\tSpeed 35.1 samples/s\tLoss 5.25795 (5.31010)\n",
      "Test: [0/0]\tTime 0.163 (0.163)\tLoss 5.3605 (5.3605)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-14-47/checkpoint.pth.tar\n",
      "Epoch: [1][0/2]\tTime 0.898s (0.898s)\tSpeed 35.6 samples/s\tLoss 5.29292 (5.29292)\n",
      "Epoch: [1][2/2]\tTime 0.736s (0.836s)\tSpeed 35.3 samples/s\tLoss 5.30711 (5.29272)\n",
      "Test: [0/0]\tTime 0.154 (0.154)\tLoss 5.3591 (5.3591)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-14-47/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-14-47/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:14:53,335]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'use_aug_transform': 0, 'lr': 1.097975098248139e-05, 'weight_decay': 5.476778159628229e-05, 'batch_size': 5}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "| parameter              | value                                                                 |\n",
      "|:-----------------------|:----------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-14-53                            |\n",
      "| use_aug_transform      | 0                                                                     |\n",
      "| n_train                | 90                                                                    |\n",
      "| optimizer_kwargs       | {'lr': 0.00010126132113067516, 'weight_decay': 4.587341971688306e-05} |\n",
      "| num_epochs             | 2                                                                     |\n",
      "| batch_size             | 32                                                                    |\n",
      "| num_workers            | 0                                                                     |\n",
      "| log_frequency          | 100                                                                   |\n",
      "| cache_images           | True                                                                  |\n",
      "| resume_from_checkpoint | False                                                                 |\n",
      "| logger                 | <RootLogger root (INFO)>                                              |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/2]\tTime 0.861s (0.861s)\tSpeed 37.1 samples/s\tLoss 5.33424 (5.33424)\n",
      "Epoch: [0][2/2]\tTime 0.727s (0.816s)\tSpeed 35.7 samples/s\tLoss 5.26256 (5.31077)\n",
      "Test: [0/0]\tTime 0.152 (0.152)\tLoss 5.3483 (5.3483)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-14-53/checkpoint.pth.tar\n",
      "Epoch: [1][0/2]\tTime 0.859s (0.859s)\tSpeed 37.2 samples/s\tLoss 5.18554 (5.18554)\n",
      "Epoch: [1][2/2]\tTime 0.714s (0.814s)\tSpeed 36.4 samples/s\tLoss 5.11551 (5.14418)\n",
      "Test: [0/0]\tTime 0.155 (0.155)\tLoss 5.3300 (5.3300)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-14-53/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-14-53/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:14:59,095]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'use_aug_transform': 0, 'lr': 0.00010126132113067516, 'weight_decay': 4.587341971688306e-05, 'batch_size': 5}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "| parameter              | value                                                                |\n",
      "|:-----------------------|:---------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-14-59                           |\n",
      "| use_aug_transform      | 0                                                                    |\n",
      "| n_train                | 90                                                                   |\n",
      "| optimizer_kwargs       | {'lr': 0.0008708943846384416, 'weight_decay': 0.0001287944875057102} |\n",
      "| num_epochs             | 2                                                                    |\n",
      "| batch_size             | 128                                                                  |\n",
      "| num_workers            | 0                                                                    |\n",
      "| log_frequency          | 100                                                                  |\n",
      "| cache_images           | True                                                                 |\n",
      "| resume_from_checkpoint | False                                                                |\n",
      "| logger                 | <RootLogger root (INFO)>                                             |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.196s (2.196s)\tSpeed 41.0 samples/s\tLoss 5.31089 (5.31089)\n",
      "Test: [0/0]\tTime 0.150 (0.150)\tLoss 5.2889 (5.2889)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-14-59/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.179s (2.179s)\tSpeed 41.3 samples/s\tLoss 4.71169 (4.71169)\n",
      "Test: [0/0]\tTime 0.157 (0.157)\tLoss 5.2473 (5.2473)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-14-59/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-14-59/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:15:04,319]\u001b[0m Trial 5 finished with value: 0.0 and parameters: {'use_aug_transform': 0, 'lr': 0.0008708943846384416, 'weight_decay': 0.0001287944875057102, 'batch_size': 7}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "| parameter              | value                                                                |\n",
      "|:-----------------------|:---------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-15-04                           |\n",
      "| use_aug_transform      | 1                                                                    |\n",
      "| n_train                | 90                                                                   |\n",
      "| optimizer_kwargs       | {'lr': 8.354418152465038e-05, 'weight_decay': 0.0002282958733169074} |\n",
      "| num_epochs             | 2                                                                    |\n",
      "| batch_size             | 256                                                                  |\n",
      "| num_workers            | 0                                                                    |\n",
      "| log_frequency          | 100                                                                  |\n",
      "| cache_images           | True                                                                 |\n",
      "| resume_from_checkpoint | False                                                                |\n",
      "| logger                 | <RootLogger root (INFO)>                                             |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.267s (2.267s)\tSpeed 39.7 samples/s\tLoss 5.30783 (5.30783)\n",
      "Test: [0/0]\tTime 0.164 (0.164)\tLoss 5.3260 (5.3260)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-04/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.162s (2.162s)\tSpeed 41.6 samples/s\tLoss 5.26634 (5.26634)\n",
      "Test: [0/0]\tTime 0.150 (0.150)\tLoss 5.3723 (5.3723)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-04/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-15-04/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:15:09,607]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 8.354418152465038e-05, 'weight_decay': 0.0002282958733169074, 'batch_size': 8}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "| parameter              | value                                                                 |\n",
      "|:-----------------------|:----------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-15-09                            |\n",
      "| use_aug_transform      | 0                                                                     |\n",
      "| n_train                | 90                                                                    |\n",
      "| optimizer_kwargs       | {'lr': 5.2203176950207926e-05, 'weight_decay': 0.0006608469542102245} |\n",
      "| num_epochs             | 2                                                                     |\n",
      "| batch_size             | 256                                                                   |\n",
      "| num_workers            | 0                                                                     |\n",
      "| log_frequency          | 100                                                                   |\n",
      "| cache_images           | True                                                                  |\n",
      "| resume_from_checkpoint | False                                                                 |\n",
      "| logger                 | <RootLogger root (INFO)>                                              |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.164s (2.164s)\tSpeed 41.6 samples/s\tLoss 5.29826 (5.29826)\n",
      "Test: [0/0]\tTime 0.157 (0.157)\tLoss 5.2980 (5.2980)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-09/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.177s (2.177s)\tSpeed 41.3 samples/s\tLoss 5.25919 (5.25919)\n",
      "Test: [0/0]\tTime 0.153 (0.153)\tLoss 5.2915 (5.2915)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-09/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-15-09/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:15:14,810]\u001b[0m Trial 7 finished with value: 0.0 and parameters: {'use_aug_transform': 0, 'lr': 5.2203176950207926e-05, 'weight_decay': 0.0006608469542102245, 'batch_size': 8}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "| parameter              | value                                                                 |\n",
      "|:-----------------------|:----------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-15-14                            |\n",
      "| use_aug_transform      | 0                                                                     |\n",
      "| n_train                | 90                                                                    |\n",
      "| optimizer_kwargs       | {'lr': 0.00027190973609510986, 'weight_decay': 2.623475215177268e-06} |\n",
      "| num_epochs             | 2                                                                     |\n",
      "| batch_size             | 64                                                                    |\n",
      "| num_workers            | 0                                                                     |\n",
      "| log_frequency          | 100                                                                   |\n",
      "| cache_images           | True                                                                  |\n",
      "| resume_from_checkpoint | False                                                                 |\n",
      "| logger                 | <RootLogger root (INFO)>                                              |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/1]\tTime 1.638s (1.638s)\tSpeed 39.1 samples/s\tLoss 5.33588 (5.33588)\n",
      "Epoch: [0][1/1]\tTime 0.719s (1.179s)\tSpeed 36.2 samples/s\tLoss 5.26081 (5.31419)\n",
      "Test: [0/0]\tTime 0.149 (0.149)\tLoss 5.3201 (5.3201)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-14/checkpoint.pth.tar\n",
      "Epoch: [1][0/1]\tTime 1.605s (1.605s)\tSpeed 39.9 samples/s\tLoss 4.99987 (4.99987)\n",
      "Epoch: [1][1/1]\tTime 0.718s (1.161s)\tSpeed 36.2 samples/s\tLoss 4.93447 (4.98097)\n",
      "Test: [0/0]\tTime 0.154 (0.154)\tLoss 5.2921 (5.2921)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-14/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-15-14/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:15:20,345]\u001b[0m Trial 8 finished with value: 0.0 and parameters: {'use_aug_transform': 0, 'lr': 0.00027190973609510986, 'weight_decay': 2.623475215177268e-06, 'batch_size': 6}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "| parameter              | value                                                                  |\n",
      "|:-----------------------|:-----------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-15-20                             |\n",
      "| use_aug_transform      | 0                                                                      |\n",
      "| n_train                | 90                                                                     |\n",
      "| optimizer_kwargs       | {'lr': 0.00015663596613405375, 'weight_decay': 1.2967688692160315e-07} |\n",
      "| num_epochs             | 2                                                                      |\n",
      "| batch_size             | 128                                                                    |\n",
      "| num_workers            | 0                                                                      |\n",
      "| log_frequency          | 100                                                                    |\n",
      "| cache_images           | True                                                                   |\n",
      "| resume_from_checkpoint | False                                                                  |\n",
      "| logger                 | <RootLogger root (INFO)>                                               |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.166s (2.166s)\tSpeed 41.5 samples/s\tLoss 5.31089 (5.31089)\n",
      "Test: [0/0]\tTime 0.150 (0.150)\tLoss 5.3487 (5.3487)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-20/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.183s (2.183s)\tSpeed 41.2 samples/s\tLoss 5.19398 (5.19398)\n",
      "Test: [0/0]\tTime 0.200 (0.200)\tLoss 5.3341 (5.3341)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-20/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-15-20/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:15:25,600]\u001b[0m Trial 9 finished with value: 0.0 and parameters: {'use_aug_transform': 0, 'lr': 0.00015663596613405375, 'weight_decay': 1.2967688692160315e-07, 'batch_size': 7}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "| parameter              | value                                                                  |\n",
      "|:-----------------------|:-----------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-15-25                             |\n",
      "| use_aug_transform      | 1                                                                      |\n",
      "| n_train                | 90                                                                     |\n",
      "| optimizer_kwargs       | {'lr': 2.3304023843831527e-05, 'weight_decay': 1.2137896081482671e-06} |\n",
      "| num_epochs             | 2                                                                      |\n",
      "| batch_size             | 32                                                                     |\n",
      "| num_workers            | 0                                                                      |\n",
      "| log_frequency          | 100                                                                    |\n",
      "| cache_images           | True                                                                   |\n",
      "| resume_from_checkpoint | False                                                                  |\n",
      "| logger                 | <RootLogger root (INFO)>                                               |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/2]\tTime 0.880s (0.880s)\tSpeed 36.4 samples/s\tLoss 5.33102 (5.33102)\n",
      "Epoch: [0][2/2]\tTime 0.727s (0.826s)\tSpeed 35.8 samples/s\tLoss 5.25842 (5.30876)\n",
      "Test: [0/0]\tTime 0.153 (0.153)\tLoss 5.3308 (5.3308)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-25/checkpoint.pth.tar\n",
      "Epoch: [1][0/2]\tTime 0.882s (0.882s)\tSpeed 36.3 samples/s\tLoss 5.29772 (5.29772)\n",
      "Epoch: [1][2/2]\tTime 0.720s (0.823s)\tSpeed 36.1 samples/s\tLoss 5.24758 (5.28264)\n",
      "Test: [0/0]\tTime 0.153 (0.153)\tLoss 5.3786 (5.3786)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-25/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-15-25/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:15:31,416]\u001b[0m Trial 10 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 2.3304023843831527e-05, 'weight_decay': 1.2137896081482671e-06, 'batch_size': 5}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "| parameter              | value                                                                 |\n",
      "|:-----------------------|:----------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-15-31                            |\n",
      "| use_aug_transform      | 1                                                                     |\n",
      "| n_train                | 90                                                                    |\n",
      "| optimizer_kwargs       | {'lr': 0.00031363927174231354, 'weight_decay': 0.0009777528461976362} |\n",
      "| num_epochs             | 2                                                                     |\n",
      "| batch_size             | 64                                                                    |\n",
      "| num_workers            | 0                                                                     |\n",
      "| log_frequency          | 100                                                                   |\n",
      "| cache_images           | True                                                                  |\n",
      "| resume_from_checkpoint | False                                                                 |\n",
      "| logger                 | <RootLogger root (INFO)>                                              |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/1]\tTime 1.612s (1.612s)\tSpeed 39.7 samples/s\tLoss 5.30885 (5.30885)\n",
      "Epoch: [0][1/1]\tTime 0.719s (1.166s)\tSpeed 36.2 samples/s\tLoss 5.25694 (5.29385)\n",
      "Test: [0/0]\tTime 0.151 (0.151)\tLoss 5.2769 (5.2769)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-31/checkpoint.pth.tar\n",
      "Epoch: [1][0/1]\tTime 1.611s (1.611s)\tSpeed 39.7 samples/s\tLoss 5.04631 (5.04631)\n",
      "Epoch: [1][1/1]\tTime 0.716s (1.164s)\tSpeed 36.3 samples/s\tLoss 4.97386 (5.02538)\n",
      "Test: [0/0]\tTime 0.165 (0.165)\tLoss 5.1888 (5.1888)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-31/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-15-31/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:15:36,958]\u001b[0m Trial 11 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.00031363927174231354, 'weight_decay': 0.0009777528461976362, 'batch_size': 6}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "| parameter              | value                                                                 |\n",
      "|:-----------------------|:----------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-15-36                            |\n",
      "| use_aug_transform      | 1                                                                     |\n",
      "| n_train                | 90                                                                    |\n",
      "| optimizer_kwargs       | {'lr': 3.385943574979552e-05, 'weight_decay': 1.1621765639118694e-05} |\n",
      "| num_epochs             | 2                                                                     |\n",
      "| batch_size             | 32                                                                    |\n",
      "| num_workers            | 0                                                                     |\n",
      "| log_frequency          | 100                                                                   |\n",
      "| cache_images           | True                                                                  |\n",
      "| resume_from_checkpoint | False                                                                 |\n",
      "| logger                 | <RootLogger root (INFO)>                                              |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/2]\tTime 0.870s (0.870s)\tSpeed 36.8 samples/s\tLoss 5.28367 (5.28367)\n",
      "Epoch: [0][2/2]\tTime 0.718s (0.816s)\tSpeed 36.2 samples/s\tLoss 5.25509 (5.29348)\n",
      "Test: [0/0]\tTime 0.152 (0.152)\tLoss 5.3314 (5.3314)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-36/checkpoint.pth.tar\n",
      "Epoch: [1][0/2]\tTime 0.870s (0.870s)\tSpeed 36.8 samples/s\tLoss 5.25721 (5.25721)\n",
      "Epoch: [1][2/2]\tTime 0.724s (0.821s)\tSpeed 35.9 samples/s\tLoss 5.25476 (5.25814)\n",
      "Test: [0/0]\tTime 0.153 (0.153)\tLoss 5.2980 (5.2980)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-36/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-15-36/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:15:42,730]\u001b[0m Trial 12 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 3.385943574979552e-05, 'weight_decay': 1.1621765639118694e-05, 'batch_size': 5}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "| parameter              | value                                                                |\n",
      "|:-----------------------|:---------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-15-42                           |\n",
      "| use_aug_transform      | 1                                                                    |\n",
      "| n_train                | 90                                                                   |\n",
      "| optimizer_kwargs       | {'lr': 0.0002808715617458979, 'weight_decay': 4.098484076449334e-05} |\n",
      "| num_epochs             | 2                                                                    |\n",
      "| batch_size             | 64                                                                   |\n",
      "| num_workers            | 0                                                                    |\n",
      "| log_frequency          | 100                                                                  |\n",
      "| cache_images           | True                                                                 |\n",
      "| resume_from_checkpoint | False                                                                |\n",
      "| logger                 | <RootLogger root (INFO)>                                             |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/1]\tTime 1.636s (1.636s)\tSpeed 39.1 samples/s\tLoss 5.30885 (5.30885)\n",
      "Epoch: [0][1/1]\tTime 0.730s (1.183s)\tSpeed 35.6 samples/s\tLoss 5.25656 (5.29374)\n",
      "Test: [0/0]\tTime 0.149 (0.149)\tLoss 5.2848 (5.2848)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-42/checkpoint.pth.tar\n",
      "Epoch: [1][0/1]\tTime 1.624s (1.624s)\tSpeed 39.4 samples/s\tLoss 5.07154 (5.07154)\n",
      "Epoch: [1][1/1]\tTime 0.717s (1.170s)\tSpeed 36.3 samples/s\tLoss 5.00621 (5.05267)\n",
      "Test: [0/0]\tTime 0.158 (0.158)\tLoss 5.2003 (5.2003)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-42/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-15-42/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:15:48,329]\u001b[0m Trial 13 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.0002808715617458979, 'weight_decay': 4.098484076449334e-05, 'batch_size': 6}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "| parameter              | value                                                                 |\n",
      "|:-----------------------|:----------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-15-48                            |\n",
      "| use_aug_transform      | 1                                                                     |\n",
      "| n_train                | 90                                                                    |\n",
      "| optimizer_kwargs       | {'lr': 0.0006316388680925723, 'weight_decay': 3.1334173638888094e-06} |\n",
      "| num_epochs             | 2                                                                     |\n",
      "| batch_size             | 128                                                                   |\n",
      "| num_workers            | 0                                                                     |\n",
      "| log_frequency          | 100                                                                   |\n",
      "| cache_images           | True                                                                  |\n",
      "| resume_from_checkpoint | False                                                                 |\n",
      "| logger                 | <RootLogger root (INFO)>                                              |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.190s (2.190s)\tSpeed 41.1 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.158 (0.158)\tLoss 5.2642 (5.2642)\n",
      "Accuracy: 0.100\n",
      "Saving best model to ./out/optuna_downstream_test_2022-12-13_12-15-48/best_model.pth.tar\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-48/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.188s (2.188s)\tSpeed 41.1 samples/s\tLoss 4.97832 (4.97832)\n",
      "Test: [0/0]\tTime 0.156 (0.156)\tLoss 5.1556 (5.1556)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-48/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-15-48/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:15:53,708]\u001b[0m Trial 14 finished with value: 0.1 and parameters: {'use_aug_transform': 1, 'lr': 0.0006316388680925723, 'weight_decay': 3.1334173638888094e-06, 'batch_size': 7}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                |\n",
      "|:-----------------------|:---------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-15-53                           |\n",
      "| use_aug_transform      | 1                                                                    |\n",
      "| n_train                | 90                                                                   |\n",
      "| optimizer_kwargs       | {'lr': 0.0007307199559327746, 'weight_decay': 7.397413069943393e-07} |\n",
      "| num_epochs             | 2                                                                    |\n",
      "| batch_size             | 128                                                                  |\n",
      "| num_workers            | 0                                                                    |\n",
      "| log_frequency          | 100                                                                  |\n",
      "| cache_images           | True                                                                 |\n",
      "| resume_from_checkpoint | False                                                                |\n",
      "| logger                 | <RootLogger root (INFO)>                                             |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.238s (2.238s)\tSpeed 40.2 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.157 (0.157)\tLoss 5.2532 (5.2532)\n",
      "Accuracy: 0.100\n",
      "Saving best model to ./out/optuna_downstream_test_2022-12-13_12-15-53/best_model.pth.tar\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-53/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.205s (2.205s)\tSpeed 40.8 samples/s\tLoss 4.93034 (4.93034)\n",
      "Test: [0/0]\tTime 0.154 (0.154)\tLoss 5.1367 (5.1367)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-53/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-15-53/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:15:59,157]\u001b[0m Trial 15 finished with value: 0.1 and parameters: {'use_aug_transform': 1, 'lr': 0.0007307199559327746, 'weight_decay': 7.397413069943393e-07, 'batch_size': 7}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                               |\n",
      "|:-----------------------|:--------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-15-59                          |\n",
      "| use_aug_transform      | 1                                                                   |\n",
      "| n_train                | 90                                                                  |\n",
      "| optimizer_kwargs       | {'lr': 0.0008439705208315901, 'weight_decay': 5.68754440406886e-07} |\n",
      "| num_epochs             | 2                                                                   |\n",
      "| batch_size             | 128                                                                 |\n",
      "| num_workers            | 0                                                                   |\n",
      "| log_frequency          | 100                                                                 |\n",
      "| cache_images           | True                                                                |\n",
      "| resume_from_checkpoint | False                                                               |\n",
      "| logger                 | <RootLogger root (INFO)>                                            |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.209s (2.209s)\tSpeed 40.7 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.168 (0.168)\tLoss 5.2413 (5.2413)\n",
      "Accuracy: 0.100\n",
      "Saving best model to ./out/optuna_downstream_test_2022-12-13_12-15-59/best_model.pth.tar\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-59/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.199s (2.199s)\tSpeed 40.9 samples/s\tLoss 4.87640 (4.87640)\n",
      "Test: [0/0]\tTime 0.154 (0.154)\tLoss 5.1172 (5.1172)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-15-59/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-15-59/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:16:04,575]\u001b[0m Trial 16 finished with value: 0.1 and parameters: {'use_aug_transform': 1, 'lr': 0.0008439705208315901, 'weight_decay': 5.68754440406886e-07, 'batch_size': 7}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                 |\n",
      "|:-----------------------|:----------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-16-04                            |\n",
      "| use_aug_transform      | 1                                                                     |\n",
      "| n_train                | 90                                                                    |\n",
      "| optimizer_kwargs       | {'lr': 0.00046181913544981253, 'weight_decay': 1.694737538484002e-07} |\n",
      "| num_epochs             | 2                                                                     |\n",
      "| batch_size             | 128                                                                   |\n",
      "| num_workers            | 0                                                                     |\n",
      "| log_frequency          | 100                                                                   |\n",
      "| cache_images           | True                                                                  |\n",
      "| resume_from_checkpoint | False                                                                 |\n",
      "| logger                 | <RootLogger root (INFO)>                                              |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.243s (2.243s)\tSpeed 40.1 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.160 (0.160)\tLoss 5.2839 (5.2839)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-04/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.196s (2.196s)\tSpeed 41.0 samples/s\tLoss 5.06202 (5.06202)\n",
      "Test: [0/0]\tTime 0.159 (0.159)\tLoss 5.1940 (5.1940)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-04/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-16-04/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:16:09,901]\u001b[0m Trial 17 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.00046181913544981253, 'weight_decay': 1.694737538484002e-07, 'batch_size': 7}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                 |\n",
      "|:-----------------------|:----------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-16-09                            |\n",
      "| use_aug_transform      | 1                                                                     |\n",
      "| n_train                | 90                                                                    |\n",
      "| optimizer_kwargs       | {'lr': 0.0005537615251918069, 'weight_decay': 3.5806397927208212e-06} |\n",
      "| num_epochs             | 2                                                                     |\n",
      "| batch_size             | 256                                                                   |\n",
      "| num_workers            | 0                                                                     |\n",
      "| log_frequency          | 100                                                                   |\n",
      "| cache_images           | True                                                                  |\n",
      "| resume_from_checkpoint | False                                                                 |\n",
      "| logger                 | <RootLogger root (INFO)>                                              |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.213s (2.213s)\tSpeed 40.7 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.172 (0.172)\tLoss 5.2734 (5.2734)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-09/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.231s (2.231s)\tSpeed 40.3 samples/s\tLoss 5.01645 (5.01645)\n",
      "Test: [0/0]\tTime 0.154 (0.154)\tLoss 5.1742 (5.1742)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-09/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-16-09/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:16:15,235]\u001b[0m Trial 18 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.0005537615251918069, 'weight_decay': 3.5806397927208212e-06, 'batch_size': 8}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                |\n",
      "|:-----------------------|:---------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-16-15                           |\n",
      "| use_aug_transform      | 1                                                                    |\n",
      "| n_train                | 90                                                                   |\n",
      "| optimizer_kwargs       | {'lr': 0.0009335227758079183, 'weight_decay': 4.988095294496526e-07} |\n",
      "| num_epochs             | 2                                                                    |\n",
      "| batch_size             | 128                                                                  |\n",
      "| num_workers            | 0                                                                    |\n",
      "| log_frequency          | 100                                                                  |\n",
      "| cache_images           | True                                                                 |\n",
      "| resume_from_checkpoint | False                                                                |\n",
      "| logger                 | <RootLogger root (INFO)>                                             |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.227s (2.227s)\tSpeed 40.4 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.154 (0.154)\tLoss 5.2320 (5.2320)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-15/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.214s (2.214s)\tSpeed 40.6 samples/s\tLoss 4.83447 (4.83447)\n",
      "Test: [0/0]\tTime 0.152 (0.152)\tLoss 5.1000 (5.1000)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-15/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-16-15/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:16:20,548]\u001b[0m Trial 19 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.0009335227758079183, 'weight_decay': 4.988095294496526e-07, 'batch_size': 7}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                 |\n",
      "|:-----------------------|:----------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-16-20                            |\n",
      "| use_aug_transform      | 1                                                                     |\n",
      "| n_train                | 90                                                                    |\n",
      "| optimizer_kwargs       | {'lr': 0.00018935948263700038, 'weight_decay': 4.599878026249776e-07} |\n",
      "| num_epochs             | 2                                                                     |\n",
      "| batch_size             | 256                                                                   |\n",
      "| num_workers            | 0                                                                     |\n",
      "| log_frequency          | 100                                                                   |\n",
      "| cache_images           | True                                                                  |\n",
      "| resume_from_checkpoint | False                                                                 |\n",
      "| logger                 | <RootLogger root (INFO)>                                              |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.213s (2.213s)\tSpeed 40.7 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.158 (0.158)\tLoss 5.3161 (5.3161)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-20/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.192s (2.192s)\tSpeed 41.1 samples/s\tLoss 5.20055 (5.20055)\n",
      "Test: [0/0]\tTime 0.156 (0.156)\tLoss 5.2643 (5.2643)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-20/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-16-20/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:16:25,866]\u001b[0m Trial 20 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.00018935948263700038, 'weight_decay': 4.599878026249776e-07, 'batch_size': 8}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                |\n",
      "|:-----------------------|:---------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-16-25                           |\n",
      "| use_aug_transform      | 1                                                                    |\n",
      "| n_train                | 90                                                                   |\n",
      "| optimizer_kwargs       | {'lr': 0.000557287775050382, 'weight_decay': 2.8738377711602186e-06} |\n",
      "| num_epochs             | 2                                                                    |\n",
      "| batch_size             | 128                                                                  |\n",
      "| num_workers            | 0                                                                    |\n",
      "| log_frequency          | 100                                                                  |\n",
      "| cache_images           | True                                                                 |\n",
      "| resume_from_checkpoint | False                                                                |\n",
      "| logger                 | <RootLogger root (INFO)>                                             |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.214s (2.214s)\tSpeed 40.6 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.156 (0.156)\tLoss 5.2731 (5.2731)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-25/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.230s (2.230s)\tSpeed 40.4 samples/s\tLoss 5.01471 (5.01471)\n",
      "Test: [0/0]\tTime 0.158 (0.158)\tLoss 5.1738 (5.1738)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-25/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-16-25/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:16:31,195]\u001b[0m Trial 21 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.000557287775050382, 'weight_decay': 2.8738377711602186e-06, 'batch_size': 7}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                |\n",
      "|:-----------------------|:---------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-16-31                           |\n",
      "| use_aug_transform      | 1                                                                    |\n",
      "| n_train                | 90                                                                   |\n",
      "| optimizer_kwargs       | {'lr': 0.0009704926284585342, 'weight_decay': 8.807239787177473e-07} |\n",
      "| num_epochs             | 2                                                                    |\n",
      "| batch_size             | 128                                                                  |\n",
      "| num_workers            | 0                                                                    |\n",
      "| log_frequency          | 100                                                                  |\n",
      "| cache_images           | True                                                                 |\n",
      "| resume_from_checkpoint | False                                                                |\n",
      "| logger                 | <RootLogger root (INFO)>                                             |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.209s (2.209s)\tSpeed 40.7 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.155 (0.155)\tLoss 5.2282 (5.2282)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-31/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.200s (2.200s)\tSpeed 40.9 samples/s\tLoss 4.81734 (4.81734)\n",
      "Test: [0/0]\tTime 0.171 (0.171)\tLoss 5.0942 (5.0942)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-31/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-16-31/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:16:36,539]\u001b[0m Trial 22 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.0009704926284585342, 'weight_decay': 8.807239787177473e-07, 'batch_size': 7}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                |\n",
      "|:-----------------------|:---------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-16-36                           |\n",
      "| use_aug_transform      | 1                                                                    |\n",
      "| n_train                | 90                                                                   |\n",
      "| optimizer_kwargs       | {'lr': 0.000464609892727983, 'weight_decay': 2.8987312195803014e-07} |\n",
      "| num_epochs             | 2                                                                    |\n",
      "| batch_size             | 128                                                                  |\n",
      "| num_workers            | 0                                                                    |\n",
      "| log_frequency          | 100                                                                  |\n",
      "| cache_images           | True                                                                 |\n",
      "| resume_from_checkpoint | False                                                                |\n",
      "| logger                 | <RootLogger root (INFO)>                                             |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.254s (2.254s)\tSpeed 39.9 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.165 (0.165)\tLoss 5.2837 (5.2837)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-36/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.241s (2.241s)\tSpeed 40.2 samples/s\tLoss 5.06062 (5.06062)\n",
      "Test: [0/0]\tTime 0.158 (0.158)\tLoss 5.1937 (5.1937)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-36/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-16-36/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:16:41,941]\u001b[0m Trial 23 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.000464609892727983, 'weight_decay': 2.8987312195803014e-07, 'batch_size': 7}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                 |\n",
      "|:-----------------------|:----------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-16-41                            |\n",
      "| use_aug_transform      | 1                                                                     |\n",
      "| n_train                | 90                                                                    |\n",
      "| optimizer_kwargs       | {'lr': 0.0006693558908695733, 'weight_decay': 1.2438329224251528e-06} |\n",
      "| num_epochs             | 2                                                                     |\n",
      "| batch_size             | 128                                                                   |\n",
      "| num_workers            | 0                                                                     |\n",
      "| log_frequency          | 100                                                                   |\n",
      "| cache_images           | True                                                                  |\n",
      "| resume_from_checkpoint | False                                                                 |\n",
      "| logger                 | <RootLogger root (INFO)>                                              |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.203s (2.203s)\tSpeed 40.9 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.154 (0.154)\tLoss 5.2603 (5.2603)\n",
      "Accuracy: 0.100\n",
      "Saving best model to ./out/optuna_downstream_test_2022-12-13_12-16-41/best_model.pth.tar\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-41/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.237s (2.237s)\tSpeed 40.2 samples/s\tLoss 4.95997 (4.95997)\n",
      "Test: [0/0]\tTime 0.155 (0.155)\tLoss 5.1489 (5.1489)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-41/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-16-41/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:16:47,397]\u001b[0m Trial 24 finished with value: 0.1 and parameters: {'use_aug_transform': 1, 'lr': 0.0006693558908695733, 'weight_decay': 1.2438329224251528e-06, 'batch_size': 7}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                  |\n",
      "|:-----------------------|:-----------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-16-47                             |\n",
      "| use_aug_transform      | 1                                                                      |\n",
      "| n_train                | 90                                                                     |\n",
      "| optimizer_kwargs       | {'lr': 0.00034306477119804403, 'weight_decay': 1.5752464229185691e-06} |\n",
      "| num_epochs             | 2                                                                      |\n",
      "| batch_size             | 256                                                                    |\n",
      "| num_workers            | 0                                                                      |\n",
      "| log_frequency          | 100                                                                    |\n",
      "| cache_images           | True                                                                   |\n",
      "| resume_from_checkpoint | False                                                                  |\n",
      "| logger                 | <RootLogger root (INFO)>                                               |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.213s (2.213s)\tSpeed 40.7 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.155 (0.155)\tLoss 5.2977 (5.2977)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-47/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.225s (2.225s)\tSpeed 40.5 samples/s\tLoss 5.12182 (5.12182)\n",
      "Test: [0/0]\tTime 0.155 (0.155)\tLoss 5.2232 (5.2232)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-47/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-16-47/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:16:52,714]\u001b[0m Trial 25 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.00034306477119804403, 'weight_decay': 1.5752464229185691e-06, 'batch_size': 8}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                |\n",
      "|:-----------------------|:---------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-16-52                           |\n",
      "| use_aug_transform      | 1                                                                    |\n",
      "| n_train                | 90                                                                   |\n",
      "| optimizer_kwargs       | {'lr': 0.000790200265970879, 'weight_decay': 5.5576103882502296e-06} |\n",
      "| num_epochs             | 2                                                                    |\n",
      "| batch_size             | 128                                                                  |\n",
      "| num_workers            | 0                                                                    |\n",
      "| log_frequency          | 100                                                                  |\n",
      "| cache_images           | True                                                                 |\n",
      "| resume_from_checkpoint | False                                                                |\n",
      "| logger                 | <RootLogger root (INFO)>                                             |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.232s (2.232s)\tSpeed 40.3 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.155 (0.155)\tLoss 5.2473 (5.2473)\n",
      "Accuracy: 0.100\n",
      "Saving best model to ./out/optuna_downstream_test_2022-12-13_12-16-52/best_model.pth.tar\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-52/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.215s (2.215s)\tSpeed 40.6 samples/s\tLoss 4.90192 (4.90192)\n",
      "Test: [0/0]\tTime 0.156 (0.156)\tLoss 5.1281 (5.1281)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-52/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-16-52/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:16:58,207]\u001b[0m Trial 26 finished with value: 0.1 and parameters: {'use_aug_transform': 1, 'lr': 0.000790200265970879, 'weight_decay': 5.5576103882502296e-06, 'batch_size': 7}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                |\n",
      "|:-----------------------|:---------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-16-58                           |\n",
      "| use_aug_transform      | 1                                                                    |\n",
      "| n_train                | 90                                                                   |\n",
      "| optimizer_kwargs       | {'lr': 0.0002052625880460964, 'weight_decay': 7.100046906207512e-06} |\n",
      "| num_epochs             | 2                                                                    |\n",
      "| batch_size             | 64                                                                   |\n",
      "| num_workers            | 0                                                                    |\n",
      "| log_frequency          | 100                                                                  |\n",
      "| cache_images           | True                                                                 |\n",
      "| resume_from_checkpoint | False                                                                |\n",
      "| logger                 | <RootLogger root (INFO)>                                             |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/1]\tTime 1.640s (1.640s)\tSpeed 39.0 samples/s\tLoss 5.30885 (5.30885)\n",
      "Epoch: [0][1/1]\tTime 0.728s (1.184s)\tSpeed 35.7 samples/s\tLoss 5.25576 (5.29351)\n",
      "Test: [0/0]\tTime 0.158 (0.158)\tLoss 5.2999 (5.2999)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-58/checkpoint.pth.tar\n",
      "Epoch: [1][0/1]\tTime 1.650s (1.650s)\tSpeed 38.8 samples/s\tLoss 5.13110 (5.13110)\n",
      "Epoch: [1][1/1]\tTime 0.728s (1.189s)\tSpeed 35.7 samples/s\tLoss 5.08355 (5.11736)\n",
      "Test: [0/0]\tTime 0.159 (0.159)\tLoss 5.2322 (5.2322)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-16-58/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-16-58/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:17:03,860]\u001b[0m Trial 27 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.0002052625880460964, 'weight_decay': 7.100046906207512e-06, 'batch_size': 6}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                |\n",
      "|:-----------------------|:---------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-17-03                           |\n",
      "| use_aug_transform      | 1                                                                    |\n",
      "| n_train                | 90                                                                   |\n",
      "| optimizer_kwargs       | {'lr': 0.0004324818416481621, 'weight_decay': 7.133576203045009e-07} |\n",
      "| num_epochs             | 2                                                                    |\n",
      "| batch_size             | 128                                                                  |\n",
      "| num_workers            | 0                                                                    |\n",
      "| log_frequency          | 100                                                                  |\n",
      "| cache_images           | True                                                                 |\n",
      "| resume_from_checkpoint | False                                                                |\n",
      "| logger                 | <RootLogger root (INFO)>                                             |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.211s (2.211s)\tSpeed 40.7 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.153 (0.153)\tLoss 5.2876 (5.2876)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-03/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.240s (2.240s)\tSpeed 40.2 samples/s\tLoss 5.07673 (5.07673)\n",
      "Test: [0/0]\tTime 0.169 (0.169)\tLoss 5.2013 (5.2013)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-03/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-17-03/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:17:09,227]\u001b[0m Trial 28 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.0004324818416481621, 'weight_decay': 7.133576203045009e-07, 'batch_size': 7}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                |\n",
      "|:-----------------------|:---------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-17-09                           |\n",
      "| use_aug_transform      | 1                                                                    |\n",
      "| n_train                | 90                                                                   |\n",
      "| optimizer_kwargs       | {'lr': 0.0006933377630325485, 'weight_decay': 5.426516787598706e-06} |\n",
      "| num_epochs             | 2                                                                    |\n",
      "| batch_size             | 256                                                                  |\n",
      "| num_workers            | 0                                                                    |\n",
      "| log_frequency          | 100                                                                  |\n",
      "| cache_images           | True                                                                 |\n",
      "| resume_from_checkpoint | False                                                                |\n",
      "| logger                 | <RootLogger root (INFO)>                                             |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.253s (2.253s)\tSpeed 39.9 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.170 (0.170)\tLoss 5.2578 (5.2578)\n",
      "Accuracy: 0.100\n",
      "Saving best model to ./out/optuna_downstream_test_2022-12-13_12-17-09/best_model.pth.tar\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-09/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.250s (2.250s)\tSpeed 40.0 samples/s\tLoss 4.94837 (4.94837)\n",
      "Test: [0/0]\tTime 0.154 (0.154)\tLoss 5.1444 (5.1444)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-09/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-17-09/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:17:14,785]\u001b[0m Trial 29 finished with value: 0.1 and parameters: {'use_aug_transform': 1, 'lr': 0.0006933377630325485, 'weight_decay': 5.426516787598706e-06, 'batch_size': 8}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                               |\n",
      "|:-----------------------|:--------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-17-14                          |\n",
      "| use_aug_transform      | 1                                                                   |\n",
      "| n_train                | 90                                                                  |\n",
      "| optimizer_kwargs       | {'lr': 0.000668545785667853, 'weight_decay': 1.882949020091153e-05} |\n",
      "| num_epochs             | 2                                                                   |\n",
      "| batch_size             | 128                                                                 |\n",
      "| num_workers            | 0                                                                   |\n",
      "| log_frequency          | 100                                                                 |\n",
      "| cache_images           | True                                                                |\n",
      "| resume_from_checkpoint | False                                                               |\n",
      "| logger                 | <RootLogger root (INFO)>                                            |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.233s (2.233s)\tSpeed 40.3 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.155 (0.155)\tLoss 5.2606 (5.2606)\n",
      "Accuracy: 0.100\n",
      "Saving best model to ./out/optuna_downstream_test_2022-12-13_12-17-14/best_model.pth.tar\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-14/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.226s (2.226s)\tSpeed 40.4 samples/s\tLoss 4.96038 (4.96038)\n",
      "Test: [0/0]\tTime 0.157 (0.157)\tLoss 5.1489 (5.1489)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-14/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-17-14/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:17:20,277]\u001b[0m Trial 30 finished with value: 0.1 and parameters: {'use_aug_transform': 1, 'lr': 0.000668545785667853, 'weight_decay': 1.882949020091153e-05, 'batch_size': 7}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                 |\n",
      "|:-----------------------|:----------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-17-20                            |\n",
      "| use_aug_transform      | 1                                                                     |\n",
      "| n_train                | 90                                                                    |\n",
      "| optimizer_kwargs       | {'lr': 0.0007587018028900769, 'weight_decay': 1.4013136518106348e-06} |\n",
      "| num_epochs             | 2                                                                     |\n",
      "| batch_size             | 128                                                                   |\n",
      "| num_workers            | 0                                                                     |\n",
      "| log_frequency          | 100                                                                   |\n",
      "| cache_images           | True                                                                  |\n",
      "| resume_from_checkpoint | False                                                                 |\n",
      "| logger                 | <RootLogger root (INFO)>                                              |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.222s (2.222s)\tSpeed 40.5 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.163 (0.163)\tLoss 5.2507 (5.2507)\n",
      "Accuracy: 0.100\n",
      "Saving best model to ./out/optuna_downstream_test_2022-12-13_12-17-20/best_model.pth.tar\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-20/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.230s (2.230s)\tSpeed 40.4 samples/s\tLoss 4.91693 (4.91693)\n",
      "Test: [0/0]\tTime 0.157 (0.157)\tLoss 5.1331 (5.1331)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-20/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-17-20/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:17:25,780]\u001b[0m Trial 31 finished with value: 0.1 and parameters: {'use_aug_transform': 1, 'lr': 0.0007587018028900769, 'weight_decay': 1.4013136518106348e-06, 'batch_size': 7}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                               |\n",
      "|:-----------------------|:--------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-17-25                          |\n",
      "| use_aug_transform      | 1                                                                   |\n",
      "| n_train                | 90                                                                  |\n",
      "| optimizer_kwargs       | {'lr': 0.0003807037432210347, 'weight_decay': 5.94579557141317e-06} |\n",
      "| num_epochs             | 2                                                                   |\n",
      "| batch_size             | 256                                                                 |\n",
      "| num_workers            | 0                                                                   |\n",
      "| log_frequency          | 100                                                                 |\n",
      "| cache_images           | True                                                                |\n",
      "| resume_from_checkpoint | False                                                               |\n",
      "| logger                 | <RootLogger root (INFO)>                                            |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.301s (2.301s)\tSpeed 39.1 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.169 (0.169)\tLoss 5.2935 (5.2935)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-25/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.261s (2.261s)\tSpeed 39.8 samples/s\tLoss 5.10278 (5.10278)\n",
      "Test: [0/0]\tTime 0.163 (0.163)\tLoss 5.2140 (5.2140)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-25/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-17-25/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:17:31,265]\u001b[0m Trial 32 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.0003807037432210347, 'weight_decay': 5.94579557141317e-06, 'batch_size': 8}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                               |\n",
      "|:-----------------------|:--------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-17-31                          |\n",
      "| use_aug_transform      | 1                                                                   |\n",
      "| n_train                | 90                                                                  |\n",
      "| optimizer_kwargs       | {'lr': 0.0006498595420914731, 'weight_decay': 2.63287516788939e-07} |\n",
      "| num_epochs             | 2                                                                   |\n",
      "| batch_size             | 128                                                                 |\n",
      "| num_workers            | 0                                                                   |\n",
      "| log_frequency          | 100                                                                 |\n",
      "| cache_images           | True                                                                |\n",
      "| resume_from_checkpoint | False                                                               |\n",
      "| logger                 | <RootLogger root (INFO)>                                            |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.256s (2.256s)\tSpeed 39.9 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.155 (0.155)\tLoss 5.2626 (5.2626)\n",
      "Accuracy: 0.100\n",
      "Saving best model to ./out/optuna_downstream_test_2022-12-13_12-17-31/best_model.pth.tar\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-31/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.229s (2.229s)\tSpeed 40.4 samples/s\tLoss 4.96944 (4.96944)\n",
      "Test: [0/0]\tTime 0.159 (0.159)\tLoss 5.1533 (5.1533)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-31/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-17-31/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:17:36,790]\u001b[0m Trial 33 finished with value: 0.1 and parameters: {'use_aug_transform': 1, 'lr': 0.0006498595420914731, 'weight_decay': 2.63287516788939e-07, 'batch_size': 7}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                |\n",
      "|:-----------------------|:---------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-17-36                           |\n",
      "| use_aug_transform      | 1                                                                    |\n",
      "| n_train                | 90                                                                   |\n",
      "| optimizer_kwargs       | {'lr': 0.0009732976075842608, 'weight_decay': 2.466432217899697e-05} |\n",
      "| num_epochs             | 2                                                                    |\n",
      "| batch_size             | 256                                                                  |\n",
      "| num_workers            | 0                                                                    |\n",
      "| log_frequency          | 100                                                                  |\n",
      "| cache_images           | True                                                                 |\n",
      "| resume_from_checkpoint | False                                                                |\n",
      "| logger                 | <RootLogger root (INFO)>                                             |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.272s (2.272s)\tSpeed 39.6 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.156 (0.156)\tLoss 5.2281 (5.2281)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-36/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.235s (2.235s)\tSpeed 40.3 samples/s\tLoss 4.81605 (4.81605)\n",
      "Test: [0/0]\tTime 0.161 (0.161)\tLoss 5.0936 (5.0936)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-36/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-17-36/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:17:42,301]\u001b[0m Trial 34 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.0009732976075842608, 'weight_decay': 2.466432217899697e-05, 'batch_size': 8}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                |\n",
      "|:-----------------------|:---------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-17-42                           |\n",
      "| use_aug_transform      | 1                                                                    |\n",
      "| n_train                | 90                                                                   |\n",
      "| optimizer_kwargs       | {'lr': 0.0005327076716613034, 'weight_decay': 1.463896581134646e-05} |\n",
      "| num_epochs             | 2                                                                    |\n",
      "| batch_size             | 64                                                                   |\n",
      "| num_workers            | 0                                                                    |\n",
      "| log_frequency          | 100                                                                  |\n",
      "| cache_images           | True                                                                 |\n",
      "| resume_from_checkpoint | False                                                                |\n",
      "| logger                 | <RootLogger root (INFO)>                                             |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/1]\tTime 1.637s (1.637s)\tSpeed 39.1 samples/s\tLoss 5.30885 (5.30885)\n",
      "Epoch: [0][1/1]\tTime 0.733s (1.185s)\tSpeed 35.5 samples/s\tLoss 5.26017 (5.29479)\n",
      "Test: [0/0]\tTime 0.158 (0.158)\tLoss 5.2421 (5.2421)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-42/checkpoint.pth.tar\n",
      "Epoch: [1][0/1]\tTime 1.645s (1.645s)\tSpeed 38.9 samples/s\tLoss 4.88082 (4.88082)\n",
      "Epoch: [1][1/1]\tTime 0.741s (1.193s)\tSpeed 35.1 samples/s\tLoss 4.76350 (4.84693)\n",
      "Test: [0/0]\tTime 0.161 (0.161)\tLoss 5.1173 (5.1173)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-42/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-17-42/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:17:47,983]\u001b[0m Trial 35 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.0005327076716613034, 'weight_decay': 1.463896581134646e-05, 'batch_size': 6}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                |\n",
      "|:-----------------------|:---------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-17-47                           |\n",
      "| use_aug_transform      | 1                                                                    |\n",
      "| n_train                | 90                                                                   |\n",
      "| optimizer_kwargs       | {'lr': 0.0002166418146753841, 'weight_decay': 2.453534214579344e-07} |\n",
      "| num_epochs             | 2                                                                    |\n",
      "| batch_size             | 128                                                                  |\n",
      "| num_workers            | 0                                                                    |\n",
      "| log_frequency          | 100                                                                  |\n",
      "| cache_images           | True                                                                 |\n",
      "| resume_from_checkpoint | False                                                                |\n",
      "| logger                 | <RootLogger root (INFO)>                                             |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.241s (2.241s)\tSpeed 40.2 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.159 (0.159)\tLoss 5.3130 (5.3130)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-47/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.228s (2.228s)\tSpeed 40.4 samples/s\tLoss 5.18646 (5.18646)\n",
      "Test: [0/0]\tTime 0.158 (0.158)\tLoss 5.2572 (5.2572)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-47/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-17-47/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:17:53,352]\u001b[0m Trial 36 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.0002166418146753841, 'weight_decay': 2.453534214579344e-07, 'batch_size': 7}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                               |\n",
      "|:-----------------------|:--------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-17-53                          |\n",
      "| use_aug_transform      | 1                                                                   |\n",
      "| n_train                | 90                                                                  |\n",
      "| optimizer_kwargs       | {'lr': 0.00013072612244288426, 'weight_decay': 3.3641472847235e-07} |\n",
      "| num_epochs             | 2                                                                   |\n",
      "| batch_size             | 128                                                                 |\n",
      "| num_workers            | 0                                                                   |\n",
      "| log_frequency          | 100                                                                 |\n",
      "| cache_images           | True                                                                |\n",
      "| resume_from_checkpoint | False                                                               |\n",
      "| logger                 | <RootLogger root (INFO)>                                            |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.253s (2.253s)\tSpeed 39.9 samples/s\tLoss 5.29415 (5.29415)\n",
      "Test: [0/0]\tTime 0.159 (0.159)\tLoss 5.3237 (5.3237)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-53/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.236s (2.236s)\tSpeed 40.3 samples/s\tLoss 5.23108 (5.23108)\n",
      "Test: [0/0]\tTime 0.158 (0.158)\tLoss 5.2798 (5.2798)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-53/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-17-53/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:17:58,759]\u001b[0m Trial 37 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.00013072612244288426, 'weight_decay': 3.3641472847235e-07, 'batch_size': 7}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                  |\n",
      "|:-----------------------|:-----------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-17-58                             |\n",
      "| use_aug_transform      | 0                                                                      |\n",
      "| n_train                | 90                                                                     |\n",
      "| optimizer_kwargs       | {'lr': 1.0845451185932476e-05, 'weight_decay': 1.0559102982418762e-07} |\n",
      "| num_epochs             | 2                                                                      |\n",
      "| batch_size             | 64                                                                     |\n",
      "| num_workers            | 0                                                                      |\n",
      "| log_frequency          | 100                                                                    |\n",
      "| cache_images           | True                                                                   |\n",
      "| resume_from_checkpoint | False                                                                  |\n",
      "| logger                 | <RootLogger root (INFO)>                                               |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/1]\tTime 1.652s (1.652s)\tSpeed 38.7 samples/s\tLoss 5.31408 (5.31408)\n",
      "Epoch: [0][1/1]\tTime 0.734s (1.193s)\tSpeed 35.4 samples/s\tLoss 5.25813 (5.29792)\n",
      "Test: [0/0]\tTime 0.157 (0.157)\tLoss 5.3015 (5.3015)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-58/checkpoint.pth.tar\n",
      "Epoch: [1][0/1]\tTime 1.656s (1.656s)\tSpeed 38.6 samples/s\tLoss 5.27968 (5.27968)\n",
      "Epoch: [1][1/1]\tTime 0.736s (1.196s)\tSpeed 35.3 samples/s\tLoss 5.29933 (5.28536)\n",
      "Test: [0/0]\tTime 0.155 (0.155)\tLoss 5.2995 (5.2995)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-17-58/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-17-58/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:18:04,456]\u001b[0m Trial 38 finished with value: 0.0 and parameters: {'use_aug_transform': 0, 'lr': 1.0845451185932476e-05, 'weight_decay': 1.0559102982418762e-07, 'batch_size': 6}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                |\n",
      "|:-----------------------|:---------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-18-04                           |\n",
      "| use_aug_transform      | 1                                                                    |\n",
      "| n_train                | 90                                                                   |\n",
      "| optimizer_kwargs       | {'lr': 0.0005790175547102811, 'weight_decay': 6.437426780622938e-07} |\n",
      "| num_epochs             | 2                                                                    |\n",
      "| batch_size             | 128                                                                  |\n",
      "| num_workers            | 0                                                                    |\n",
      "| log_frequency          | 100                                                                  |\n",
      "| cache_images           | True                                                                 |\n",
      "| resume_from_checkpoint | False                                                                |\n",
      "| logger                 | <RootLogger root (INFO)>                                             |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n",
      "Epoch: [0][0/0]\tTime 2.232s (2.232s)\tSpeed 40.3 samples/s\tLoss 5.30783 (5.30783)\n",
      "Test: [0/0]\tTime 0.175 (0.175)\tLoss 5.2855 (5.2855)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-18-04/checkpoint.pth.tar\n",
      "Epoch: [1][0/0]\tTime 2.245s (2.245s)\tSpeed 40.1 samples/s\tLoss 5.00907 (5.00907)\n",
      "Test: [0/0]\tTime 0.160 (0.160)\tLoss 5.3083 (5.3083)\n",
      "Accuracy: 0.000\n",
      "Saving checkpoint to ./out/optuna_downstream_test_2022-12-13_12-18-04/checkpoint.pth.tar\n",
      "Saving final model to ./out/optuna_downstream_test_2022-12-13_12-18-04/final_model.pth.tar\n",
      "\u001b[32m[I 2022-12-13 12:18:09,856]\u001b[0m Trial 39 finished with value: 0.0 and parameters: {'use_aug_transform': 1, 'lr': 0.0005790175547102811, 'weight_decay': 6.437426780622938e-07, 'batch_size': 7}. Best is trial 14 with value: 0.1.\u001b[0m\n",
      "| parameter              | value                                                                 |\n",
      "|:-----------------------|:----------------------------------------------------------------------|\n",
      "| experiment_id          | optuna_downstream_test_2022-12-13_12-18-09                            |\n",
      "| use_aug_transform      | 0                                                                     |\n",
      "| n_train                | 90                                                                    |\n",
      "| optimizer_kwargs       | {'lr': 1.7002196262117344e-05, 'weight_decay': 1.878638076218712e-07} |\n",
      "| num_epochs             | 2                                                                     |\n",
      "| batch_size             | 128                                                                   |\n",
      "| num_workers            | 0                                                                     |\n",
      "| log_frequency          | 100                                                                   |\n",
      "| cache_images           | True                                                                  |\n",
      "| resume_from_checkpoint | False                                                                 |\n",
      "| logger                 | <RootLogger root (INFO)>                                              |\n",
      "Device: cpu\n",
      "Number of training images: \t 90\n",
      "Number of validation images: \t 10\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from src.utils import load_best_model\n",
    "from src.models import OurPretextNetwork\n",
    "from src.optuna import create_optuna_objective\n",
    "\n",
    "# specify experiment id to load pretext model from\n",
    "PRETEXT_EXPERIMENT_ID = \"dustin_lr_5e5\"\n",
    "\n",
    "# load pretext model\n",
    "pretext_model = load_best_model(PRETEXT_EXPERIMENT_ID, OurPretextNetwork(backbone=\"resnet18\"))\n",
    "\n",
    "RUN_DOWNSTREAM_PARAMS = {\n",
    "    \"experiment_id\": \"optuna_downstream_test\",\n",
    "    \"pretext_model\": pretext_model,\n",
    "    \"use_aug_transform\": (\"int\", 0, 1),\n",
    "    \"optimizer_kwargs\": {\n",
    "        \"lr\": (\"float-log\", 1e-5, 1e-3),\n",
    "        \"weight_decay\": (\"float-log\", 1e-7, 1e-3),\n",
    "    },\n",
    "    \"batch_size\": (\"int-log\", 5, 8),\n",
    "    \"cache_images\": True,\n",
    "    \"num_workers\": 0,\n",
    "    \"tiny_imagenet_info\": tiny_imagenet_info[:100],\n",
    "    \"n_train\": 90,\n",
    "    \"num_epochs\": 2,\n",
    "}\n",
    "\n",
    "# maximal number of trials to perform\n",
    "N_TRIALS = 1e9\n",
    "# stops search if last trial ended more than TIMEOUT seconds after the start\n",
    "TIMEOUT = 1e9\n",
    "\n",
    "# create objective function\n",
    "objective = create_optuna_objective(RUN_DOWNSTREAM_PARAMS)\n",
    "\n",
    "# create study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# run study\n",
    "study.optimize(objective, n_trials=N_TRIALS, timeout=TIMEOUT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
